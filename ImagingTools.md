# Ontario Brain Institute Imaging Tools

Please select the imaging tool you'd like to look at:

    
    
<details>
<summary>MRI</summary> 
    &nbsp  
    <blockquote><details><summary> Data Collection Pipelines</summary>
MRI data is collected and processed in the MRI scanner before undergoing data curation.
</details></blockquote>

<blockquote><details><summary> Data Curation and Processing Pipelines</summary>
&nbsp 
    
| Tool/Pipeline | Description | Requirements | Compute Location | Research Program(s) |
| ---------------- | ----------- | --------------------------- | ----------- | ---------|
| Naming convention pipeline | Pipeline that re-names data to be more easily processed on SPReD.<details><summary>License</summary>Creative Commons Attribution 3.0</details> | N/A | [Brain-CODE](https://www.braincode.ca/) | All |
| Scan Aquisition Pipeline | Pipeline that checks to see if there's a scan acquisition protocol which outlines specific criteria for scans.<details><summary>License</summary>Creative Commons Attribution 3.0</details> | N/A |[Brain-CODE](https://www.braincode.ca/) | All |
| [fBIRN](https://www.nitrc.org/projects/fbirn/) | Quality control for any changes in function in fMRI. Stores data in HTML file. Used for non-human/phantom data. <details><summary>License</summary>BSD and BIRN</details> | N/A | At the lab | All |
| [MRIQC](https://github.com/nipreps/mriqc/tree/c57059ee82c2bf07d188dbb588407a41116a1a61) | Program run on human brain scans and structural scans to provide summary variables. Is used to track outliers and indicate any potential problems in MRI function. Stores data in sessions on SPReD. Designed originally to handle large datasets.<details><summary>License</summary>3-clause BSD</details> <details><summary>Tool Citation(s) </summary>    Esteban O, Birman D, Schaer M, Koyejo OO, Poldrack RA, Gorgolewski KJ; MRIQC: Advancing the Automatic Prediction of Image Quality in MRI from Unseen Sites; PLOS ONE 12(9):e0184661; doi:[10.1371/journal.pone.0184661](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184661).</details> <details><summary>Relevant Publications</summary>[Esteban et al., 2017](https://doi.org/10.1101/216671), [Esteban et al.,2018](https://doi.org/10.1007/978-3-030-01364-6_21), [Sánchez et al., 2021]( https://doi.org/10.1101/2021.02.01.428681), [Provins et al., 2022](https://doi.org/10.31219/osf.io/8mcyz), [Reguig et al., 2022](https://doi.org/10.48550/arXiv.2205.15898)</details> | Large size CPU, ~1 GB of memory/task |  &emsp;&emsp;&emsp;&emsp; [Brain-CODE](https://www.braincode.ca/) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | CAN-BIND, ONDRI |
| [ANT](http://stnava.github.io/ANTs/) | Pipeline for registration to a template image (normalization). <details><summary>License</summary>Apache Version 2.0 </details> <details><summary>Tool Citation(s) </summary>Tustison, N. J., Cook, P. A., Klein, A., Song, G., Das, S. R., Duda, J. T., Kandel, B. M., van Strien, N., Stone, J. R., Gee, J. C., &amp; Avants, B. B. (2014). Large-scale evaluation of ants and freesurfer cortical thickness measurements. NeuroImage, 99, 166–179. [https://doi.org/10.1016/j.neuroimage.2014.05.044](https://www.sciencedirect.com/science/article/pii/S1053811914004091?via%3Dihub) </details> <details><summary>Relevant Publications</summary>[Walimuni et al., 2011](https://doi.org/10.1016/j.compbiomed.2010.10.009), [Sanchez et al., 2012]( https://doi.org/10.1080/87565641.2012.688900), [Hart et al., 2017](https://doi.org/10.1016/j.nicl.2017.04.026), [Wang et al., 2017]( https://www.frontiersin.org/articles/10.3389/fninf.2017.00017), [Birchfield et al., 2022](https://doi.org/10.48550/arXiv.2204.03576) </details> | N/A | [Brain-CODE](https://www.braincode.ca/) | CAN-BIND, ONDRI|
| [Free Surfer - recon-all function](https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all) | Function that conduct measurements of volumetric/thickness in all brain regions and looks at volume of grey matter, white matter, CSF in the brain. Takes 20 minutes per session. All results stored in session. <details><summary>License</summary>GNU General Public License Version 2.0 </details> <details><summary>Tool Citation(s) </summary> Citation will depend on what the recon-all function was used for. Citation information can be found [here](https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation).</details> <details><summary>Relevant Publications</summary> [Keller et al., 2012](https://doi.org/10.1007/s12021-012-9147-0), [Ellis et al., 2016](https://doi.org/10.1186/s13742-016-0147-0-o), [Muschelli et al., 2018](https://doi.org/10.12688/f1000research.14361.1), [Wu et al., 2018](https://doi.org/10.1002/hbm.24213), [Hou et al., 2020](https://doi.org/10.1371/journal.pone.0230754) </details>| Linux/OSX Operating Systems, 2GHz or faster processor, >4GB RAM, 3D Graphics Card with accelerated OpenGL drivers  | Frontenac | CAN-BIND, ONDRI|
| Scan Rating Service with notification | Service which notifies researcher to rate the scan. Once done for each scan, a report is generated with the ratings of all scans. All metadata is compared against a set of known parameters and deviations are flagged. <details><summary>License</summary>Creative Commons Attribution 3.0</details> | N/A | [Brain-CODE](https://www.braincode.ca/) | CAN-BIND, ONDRI |
| [OPPNI Pipeline](https://github.com/strotherlab/oppni) | Pipeline used for fMRI pre-processing. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s) </summary> Strother SC, Anderson J, Hansen LK, Kjems U, Kustra R et al. (2002): The Quantitative Evaluation of Functional Neuroimaging Experiments: The NPAIRS Data Analysis Framework. NeuroImage 15:747–771 </details> <details><summary> Relevant Publications</summary>[Strother et al., 2002](https://doi.org/10.1006/nimg.2001.1034), [Karimpoor et al., 2017](https://www.frontiersin.org/articles/10.3389/fnhum.2017.00496), [Karimpoor et al., 2018](https://www.frontiersin.org/articles/10.3389/fnhum.2018.00030), [Theyers et al., 2021](https://www.frontiersin.org/articles/10.3389/fpsyt.2021.617997)</details> | Large size CPU | Frontenac | CAN-BIND, ONDRI |
| [Freesurfer](https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferBeginnersGuide) | Set of software tools for study of cortical and subcortical anatomy. Similar function to CIVET. <details><summary>License</summary>[Software License](https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense)</details><details><summary>Tool Citation(s)</summary>Citation will depend on what the recon-all function was used for. Citation information can be found [here](https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferMethodsCitation).</details><details><summary>Relevant Publications</summary>[Tae et al., 2008](https://doi.org/10.1007/s00234-008-0383-9), [Fischl, 2012](https://doi.org/10.1016/j.neuroimage.2012.01.021), [Gronenschild et al., 2012](https://doi.org/10.1371/journal.pone.0038234), [Wisse et al., 2014](https://www.frontiersin.org/articles/10.3389/fnagi.2014.00261)</details>| Linux/OSX Operating Systems, 2GHz or faster processor, >4GB RAM, 3D Graphics Card with accelerated OpenGL drivers | At the lab | CAN-BIND, POND |    
| [ICN](https://www.nitrc.org/projects/icn_atlas/) | Software that uses fMRI data to create a functional network. Was used by CAN-BIND researchers to isolates 10 different networks. <details><summary>License</summary>Creative Commons Attribution 4.0</details> <details><summary>Tool Citation(s) </summary> Kozák, L. R., van Graan, L. A., Chaudhary, U. J., Szabó, Á. G., &amp; Lemieux, L. (2017). ICN_Atlas: Automated description and quantification of functional MRI activation patterns in the framework of Intrinsic Connectivity Networks. NeuroImage, 163, 319–341. [https://doi.org/10.1016/j.neuroimage.2017.09.014](https://doi.org/10.1016/j.neuroimage.2017.09.014) </details> <details><summary>Relevant Publications</summary> [Bushov et al., 2020](https://doi.org/10.1016/j.procs.2020.02.121), [Bukhari-Parlakturk et al., 2021](https://doi.org/10.1101/2021.05.14.21257239), [Marstaller et al., 2021](https://doi.org/10.1002/hbm.25199), [Vaudano et al., 2021](https://doi.org/10.1007/s10548-021-00857-x), [Elin et al., 2022](https://doi.org/10.3389/fnhum.2022.791577) </details> | N/A | At the lab | CAN-BIND |
| [MIST Atlas](https://simexp.github.io/multiscale_dashboard/index.html) | Atlas that contains parcellation of MRI images. <details><summary>License</summary> atlas can be accessed on neurovalt, which has an MIT License</details> <details><summary>Tool Citation(s) </summary> Urchs, Sebastian; Armoza, Jonathan; Benhajali, Yassine; St-Aubin, Jolène; Orban, Pierre; Bellec, Pierre (2017): MIST: A multi-resolution parcellation of functional networks. figshare. Dataset. https://doi.org/10.6084/m9.figshare.5633638.v1  </details> <details><summary>Relevant Publications</summary>[Combrisson et al., 2019](https://www.frontiersin.org/articles/10.3389/fninf.2019.00014), [Urchs et al., 2019](https://doi.org/10.12688/mniopenres.12767.2), [Dadi et al., 2020](https://doi.org/10.1016/j.neuroimage.2020.117126), [Spisak et al., 2020](https://doi.org/10.1038/s41467-019-13785-z), [Nogovitsyn et al., 2022](https://www.sciencedirect.com/science/article/abs/pii/S0920996421005259)</details> | N/A | At the lab | CAN-BIND | 
| EPInorm | **seems to be an approach rather than a software/tool** Tool used for spatial normalization on both the resting state and task fMRI data <details><summary>License</summary></details> <details><summary>Tool Citation(s) </summary>  </details> <details><summary>Relevant Publications</summary> </details> | N/A | At the lab | CAN-BIND |
| [afni_refacer](https://github.com/PennLINC/afni_refacer) | MRI Defacing tool that uses a pre-defined mask aligned using AFNI 3dAllineate and an MNI template. <details><summary>License</summary>MIT License</details> <details><summary>Tool Citation(s) </summary> Cox RW. AFNI: Software for analysis and visualization of functional magnetic resonance neuroimages. Comput Biomed Res. (1996) 29:162–173. </details> <details><summary>Relevant Publications</summary>[Cox, 1996](https://doi.org/10.1006/cbmr.1996.0014), [Gießler et al., 2021](https://doi.org/10.1515/cdbme-2021-1028), [Theyers et al., 2021](https://www.frontiersin.org/articles/10.3389/fpsyt.2021.617997), [Rubbert et al., 2022](https://doi.org/10.1186/s13244-022-01195-7)</details> | N/A | At the lab | CAN-BIND |   
| [deepdefacer](https://pypi.org/project/deepdefacer/) | MRI Defacing tool that utilizes a pre=defined model of facial probabilities to calculate the probabilities of facial features within a region. These probabilities are then used to create a binary mask that is used to remove facial features. <details><summary>License</summary>MIT License</details> <details><summary>Tool Citation(s) </summary> Khazane A, Hoachuck J, Gorgolewski KJ, Poldrack RA. DeepDefacer: automatic removal of facial features from MR scans via U-net image segmentation. arXiv. (2019). </details> <details><summary>Relevant Publications</summary> [Gießler et al., 2021](https://doi.org/10.1515/cdbme-2021-1028), [Theyers et al., 2021](https://www.frontiersin.org/articles/10.3389/fpsyt.2021.617997), [Khazane et al., 2022](http://arxiv.org/abs/2205.15536)</details> | N/A | At the lab | CAN-BIND |
| [mri_deface](https://surfer.nmr.mgh.harvard.edu/fswiki/mri_deface)  | MRI Defacing tool that assigns the probability of a voxen being either a face or a brain and removes voxels that have a non-zero probability of being a face but zero probability of being a brain. <details><summary>License</summary>[Software License](https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferSoftwareLicense)</details> <details><summary>Tool Citation(s) </summary> Bischoff-Grethe A, Ozyurt IB, Busa E, Quinn BT, Fennema-Notestine C, Clark CP, et al. A technique for the deidentification of structural brain MR images. Hum Brain Mapp. (2007) 28:892–903. doi: 10.1002/hbm.20312 </details> <details><summary>Relevant Publications</summary> [Bischoff‐Grethe et al., 2007](https://doi.org/10.1002/hbm.20312), [Schwarz et al., 2020](https://doi.org/10.1002/alz.045157), [Buimer et al., 2021](https://doi.org/10.1002/hbm.25459), [Schwarz et al., 2021](https://doi.org/10.1016/j.neuroimage.2021.117845), [Theyers et al., 2021](https://www.frontiersin.org/articles/10.3389/fpsyt.2021.617997) </details> | [FreeSurfer](https://github.com/freesurfer/freesurfer) | At the lab | CAN-BIND |
| [mridefacer](https://github.com/mih/mridefacer) | MRI Defacing tool that skull strips input MRI scans and aligns the result with a pre-defined mask using FSL-FLIRT and a template T1 brain. The mask is then applied to the original mask to remove face and ear voxels. <details><summary>License</summary>MIT License</details> <details><summary>Tool Citation(s) </summary> In-text Citation: (https://github.com/mih/mridefacer) </details> <details><summary>Relevant Publications</summary>[Buimer et al., 2021](https://doi.org/10.1002/hbm.25459), [Herholz et al., 2021](https://doi.org/10.21105/joss.03169), [Theyers et al., 2021](https://www.frontiersin.org/articles/10.3389/fpsyt.2021.617997) </details> | [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL) | At the lab | CAN-BIND |
| [pydeface](https://github.com/poldracklab/pydeface) | MRI Defacing tool that uses FSL-FLIRT to align the pre-defined mask and a template T1 structural scan to the input MRI scan and remove face voxels. <details><summary>License</summary>MIT License</details> <details><summary>Tool Citation(s) </summary> Gulban OF, Nielson D, Poldrack R, Lee J, Gorgolewski C, Vanessasaurus, Ghosh S. poldracklab/pydeface: v2.0.0 (Version v2.0.0). Zenodo. (2019). doi: 10.5281/zenodo/3524401 </details> <details><summary>Relevant Publications</summary> [Schwarz et al., 2020](https://doi.org/10.1002/alz.045157), [Theyers et al., 2021](https://www.frontiersin.org/articles/10.3389/fpsyt.2021.617997), [Bhalerao et al., 2022](https://doi.org/10.1016/j.neurad.2021.03.001), [Rubbert et al., 2022](https://doi.org/10.1186/s13244-022-01195-7), [Sahlsten et al., 2022](https://doi.org/10.1101/2022.01.22.22269695)</details> | [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL), Python 3, [NumPy](https://numpy.org/), [NiBabel](https://nipy.org/nibabel/), [Nipype](https://nipype.readthedocs.io/en/latest/) | At the lab | CAN-BIND |   
| [quickshear](https://github.com/nipy/quickshear) | MRI Defacing tool that uses a previously created brain mask to draw a plane that divides the face and brain and removes all the voxels on the face side. <details><summary>License</summary>BSD 3 Clause License</details> <details><summary>Tool Citation(s) </summary> Schimke N, Kuehler M, Hale J. Preserving privacy in structural neuroimages. In: Li Y, editor. Data and Applications Security and Privacy XXV Lecture Notes in Computer Science. Berlin; Heidelberg: Springer (2011). p. 301–8. doi: 10.1007/978-3-642-22348-8_26 </details> <details><summary>Relevant Publications</summary> [Schimke & Hale, 2011](https://www.researchgate.net/profile/J-Hale/publication/262319696_Quickshear_defacing_for_neuroimages/links/570b97ee08aed09e917516b1/Quickshear-defacing-for-neuroimages.pdf), [de Sitter et al., 2020](https://doi.org/10.1007/s00330-019-06459-3), [Herholz et al., 2021](https://joss.theoj.org/papers/10.21105/joss.03169.pdf), [Theyers et al., 2021](https://www.frontiersin.org/articles/10.3389/fpsyt.2021.617997) </details> | N/A | At the lab | CAN-BIND |
| [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php) |Tool aided by an overlay of the subject’s gray matter tissue probability map to perform voxel-wise segmentation <details><summary>License</summary>GNU General Public License</details> <details><summary>Tool Citation(s) </summary> Paul A. Yushkevich, Joseph Piven, Heather Cody Hazlett, Rachel Gimpel Smith, Sean Ho, James C. Gee, and Guido Gerig. User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability. Neuroimage 2006 Jul 1;31(3):1116-28. </br><br> Authors also request to include the link to the ITK-SNAP website (http://www.itksnap.org/). </details> <details><summary>Relevant Publications</summary>[Yushkevich et al., 2006](https://doi.org/10.1016/j.neuroimage.2006.01.015), [Fedorov et al., 2012](https://doi.org/10.1016/j.mri.2012.05.001), [Gomes et al., 2020](https://doi.org/10.1007/s11282-019-00397-y), [Ngo et al., 2021](https://doi.org/10.3390/diagnostics11101890), [Suh et al., 2021](https://www.sciencedirect.com/science/article/pii/S0306453021002225?via%3Dihub) </details> | N/A | At the lab | CAN-BIND |
| [SPM12 - VBM-Segment tool](https://www.fil.ion.ucl.ac.uk/~john/misc/VBMclass10.pdf) | SPM Tool used to perform voxel-wise segmentation <details><summary>License</summary>GNU General Public License</details> <details><summary>Tool Citation(s) </summary> Statistical Parametric Mapping: The Analysis of Functional Brain Images—1st Edition. (n.d.). Retrieved August 8, 2022, from https://www.elsevier.com/books/statistical-parametric-mapping-the-analysis-of-functional-brain-images/penny/978-0-12-372560-8 </details> <details><summary>**Relevant Publications**</summary> </details> | MATLAB | At the lab | CAN-BIND | 
| [SABRE](https://sabre.brainlab.ca/docs/index.html#) | Pipeline used for the identification of volumetrics in lesion data for structural MRI images. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s) </summary> Dade L.A., Gao F.Q., Kovacevic N., Roy P., Rockel C., O'Toole C.M., Lobaugh N.J., Feinstein A., Levine B., Black S.E.  (2004).  Semiautomatic brain region extraction: a method of parcellating brain regions from structural magnetic resonance images. Neuroimage, 22, 1492-502. </details> <details><summary>Relevant Publications</summary> [Dade et.al., 2004](https://doi.org/10.1016/j.neuroimage.2004.03.023), [Ramirez et.al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.013), [Ramirez et.al., 2013](https://doi.org/10.1007/s10548-012-0228-z), [Ramirez et.al., 2020](https://www.frontiersin.org/articles/10.3389/fneur.2020.00847) </details> | N/A | At the lab | ONDRI |
| [Lesion Explorer](https://sabre.brainlab.ca/docs/processing/stage7.html#lesion-explorer-le) | Tool used for segmentation of regions of interest, automatic identification of white matter hyperintensities, and capturing of enlarged periventricular spaces in DTI data. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s) </summary> Ramirez, J., Scott, C. J. M., McNeely, A. A., Berezuk, C., Gao, F., Szilagyi, G. M., & Black, S. E. (2014). Lesion Explorer: A Video-guided, Standardized Protocol for Accurate and Reliable MRI-derived Volumetrics in Alzheimer’s Disease and Normal Elderly. JoVE (Journal of Visualized Experiments), 86, e50887. https://doi.org/10.3791/50887 </br><br>Ramirez, J., Gibson, E., Quddus, A., Lobaugh, N. J., Feinstein, A., Levine, B., Scott, C. J. M., Levy-Cooperman, N., Gao, F. Q., & Black, S. E. (2011). Lesion Explorer: A comprehensive segmentation and parcellation package to obtain regional volumetrics for subcortical hyperintensities and intracranial tissue. NeuroImage, 54(2), 963–973. https://doi.org/10.1016/j.neuroimage.2010.09.013 </details><details><summary>Relevant Publications</summary> [Ramirez et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.013), [Ramirez et al., 2013](https://doi.org/10.1007/s10548-012-0228-z), [Ramirez et al., 2014](https://doi.org/10.3233/JAD-132528), [Haddad et al., 2019](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6924651/) </details>| N/A | At the lab | ONDRI |
| [FLEX](https://sabre.brainlab.ca/docs/processing/stage7.html#fuzzy-lesion-extractor-flex-coming-soon) (Coming soon!) | Tool used for segmentation of regions of interest and automatic identification of white matter hyperintensities in DTI data. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s)</summary>Gibson E., Gao F., Black S.E., Lobaugh N.J.  (2010).  Automatic segmentation of white matter hyperintensities in the elderly using FLAIR images at 3T. Journal of Magnetic Resonance Imaging, 31, 1311-22.</details> <details><summary>Relevant Publications</summary> [Borghesani et al., 2013](https://doi.org/10.1016/j.neuropsychologia.2013.03.005), [Makedonov et al., 2013](https://doi.org/10.1371/journal.pone.0067652), [Huang et al., 2014](https://doi.org/10.1016/j.psyneuen.2013.09.027), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details> | N/A | At the lab | ONDRI |
| [Sunnybrook Modified ITK-SNAP](https://github.com/sbips/itksnapsb) | Software that allows for editing and viewing of structural MRI data. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s) </summary> Yushkevich, P. A., Piven, J., Hazlett, H. C., Smith, R. G., Ho, S., Gee, J. C., & Gerig, G. (2006). User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability. NeuroImage, 31(3), 1116–1128. https://doi.org/10.1016/j.neuroimage.2006.01.015 </details> <details><summary>Relevant Publications</summary>[Yushkevich et al., 2006](https://doi.org/10.1016/j.neuroimage.2006.01.015), [Ramirez et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.013), [Lam et al., 2018](https://doi.org/10.1016/j.jns.2017.11.007), [Ramirez et al., 2020](https://www.frontiersin.org/articles/10.3389/fneur.2020.00847)</details> | N/A | At the lab | ONDRI |
| [ANALYZE Software](https://analyzedirect.com) | Software used for manual editing and checking procedures of structural MRI data. <details><summary>**License**</summary>Not sure...</details> <details><summary>**Tool Citation(s)** </summary> Is it needed? </details> <details><summary>Relevant Publications</summary> [Dade et.al., 2004](https://www.sciencedirect.com/science/article/pii/S1053811904001612?casa_token=LM8jd4F76UIAAAAA:MaSU1U3Hq636IU-0u1ASeyhpNFNmolFRc51fH9tSOUvwsjPvDe-JZhEgpMLY_n7oZgMYnRz1uvI), [Gibson et.al., 2010](https://onlinelibrary.wiley.com/doi/full/10.1002/jmri.22004), [Nestor et.al., 2012](https://www.sciencedirect.com/science/article/pii/S1053811912010853?casa_token=jPNTFVIQswoAAAAA:C9rVpy4jd0rnP1CtIQxNK-0BHaixLJ-NB-q5BubDvcjLkWWG4BCYnxpLmsEPlts503Z-opFHgfo), [Ramirez et.al., 201](https://content.iospress.com/articles/journal-of-alzheimers-disease/jad132528)5 </details> | N/A | At the lab | ONDRI |
| [FSL - FLIRT](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT) | Tool that is used for intra and inter modal brain image registration. <details><summary>License</summary> Oxford License</details> <details><summary>Tool Citation(s) </summary> M. Jenkinson and S.M. Smith. A global optimisation method for robust affine registration of brain images. Medical Image Analysis, 5(2):143-156, 2001.</br> <br>M. Jenkinson, P.R. Bannister, J.M. Brady, and S.M. Smith. Improved optimisation for the robust and accurate linear registration and motion correction of brain images. NeuroImage, 17(2):825-841, 2002.</br> <br>Greve, D.N. and Fischl, B. Accurate and robust brain image alignment using boundary-based registration. NeuroImage, 48(1):63-72, 2009. </br> </details> <details><summary>Relevant Publications</summary>[Jenkinson & Smith, 2001](https://doi.org/10.1016/s1361-8415(01)00036-6), [Smith et al., 2004](https://doi.org/10.1016/j.neuroimage.2004.07.051), [Lancaster et al., 2007](https://doi.org/10.1002/hbm.20345), [Ramirez et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.013), [Jenkinson et al., 2012](https://doi.org/10.1016/j.neuroimage.2011.09.015), [Muschelli et al., 2015](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4911193/) </details> | >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI |
| [FSL - BET](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET) | Tool that is used to extract the intra-cranial volume for each subject by removal of the skull and infratentorial structures. <details><summary>License</summary> Oxford License </details> <details><summary>Tool Citation(s) </summary> S.M. Smith. Fast robust automated brain extraction. Human Brain Mapping, 17(3):143-155, November 2002. </br> <br>If skull and scalp surface extraction functions are also used, please also reference the following:</br> <br> M. Jenkinson, M. Pechaud, and S. Smith. BET2: MR-based estimation of brain, skull and scalp surfaces. In Eleventh Annual Meeting of the Organization for Human Brain Mapping, 2005. </details> <details><summary>Relevant Publications</summary> [Smith et al., 2004](https://doi.org/10.1016/j.neuroimage.2004.07.051), [Smith et al., 2006](https://doi.org/10.1016/j.neuroimage.2006.02.024), [Nestor et al., 2013](https://doi.org/10.1016/j.neuroimage.2012.10.081), [Cengiz et al., 2022](https://doi.org/10.1007/s10334-022-01030-6), [Diaz-Hurtado et al., 2022](https://doi.org/10.1007/s00234-022-03019-3) </details> | >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI |
| [N3 Software](https://github.com/BIC-MNI/N3) | Software that corrects for intensity nonuniformity in MRI data by using nonparametric nonuniform intensity normalization. <details><summary>License</summary> https://github.com/BIC-MNI/N3/blob/master/COPYING </details> <details><summary>Tool Citation(s) </summary> Sled JG, Zijdenbos AP, Evans AC. A nonparametric method for automatic correction of intensity nonuniformity in MRI data. IEEE Trans Med Imaging 1998;17:87–97. </details> <details><summary>Relevant Publications</summary> [Jones & Wong, 2002](https://doi.org/10.1117/12.467069), [Zhuge et al., 2009](https://doi.org/10.1016/j.compmedimag.2008.09.004), [Gibson et al., 2010](https://doi.org/10.1002/jmri.22004), [Tustison et al., 2010](https://doi.org/10.1109/TMI.2010.2046908), [Lin et al., 2011](https://doi.org/10.1118/1.3519869), [Larsen et al., 2014](https://doi.org/10.1007/978-3-319-12289-2_1) </details> | [MINC](https://www.mcgill.ca/bic/software/minc) and [netCDF](https://www.unidata.ucar.edu/software/netcdf/) packages, [Perl](https://www.perl.org/), [mni_perllib](https://packages.bic.mni.mcgill.ca/tgz/) library | At the lab | ONDRI |
| [FSL - FAST](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FAST?highlight=%28mfast%29) (Previously mfast) | Software used for bias correction and to correct intensity inhomogeneities present in MRI data. <details><summary>License</summary> Oxford License</details> <details><summary>Tool Citation(s) </summary> Zhang, Y. and Brady, M. and Smith, S. Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm. IEEE Trans Med Imag, 20(1):45-57, 2001. </details> <details><summary>Relevant Publications</summary> [Smith et al., 2004]( https://doi.org/10.1016/j.neuroimage.2004.07.051), [Gibson et al., 2010](https://doi.org/10.1002/jmri.22004), [Glasser et al., 2013](https://doi.org/10.1016/j.neuroimage.2013.04.127), [Droby et al., 2021](https://doi.org/10.1371/journal.pone.0254597) </details> | >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI |
| [SPM Software](https://www.fil.ion.ucl.ac.uk/spm/) | Collection of MATLAB functions and subroutines that uses a thresholded probabilistic white matter template to create a white matter mask. <details><summary>License</summary>GNU General Public License Version 2.0</details> <details><summary>Tool Citation(s) </summary>Litvak, V., Mattout, J., Kiebel, S., Phillips, C., Henson, R., Kilner, J., Barnes, G., Oostenveld, R., Daunizeau, J., Flandin, G., Penny, W., & Friston, K. (2011). EEG and MEG Data Analysis in SPM8. Computational Intelligence and Neuroscience, 2011, e852961. https://doi.org/10.1155/2011/852961</details> <details><summary>Relevant Publications</summary> [Tzourio-Mazoyer et al., 2002](https://doi.org/10.1006/nimg.2001.0978), [Ashburner, 2009](https://doi.org/10.1016/j.mri.2009.01.006), [Gibson et al., 2010](https://doi.org/10.1002/jmri.22004), [Kazemi & Noorizadeh, 2014](https://pubmed.ncbi.nlm.nih.gov/25505764/) </details> | MATLAB | At the lab | ONDRI |
| [Standards (Shiny) App](https://github.com/ondri-nibs/standards_app) | Performs standard checks on ONDRI data <details><summary>License</summary>GNU General Public License Version 3.1</details> | R, Rstudio | At the lab | ONDRI| 
| [Data Preparation (Shiny) App](https://github.com/ondri-nibs/dataprep_app) | Prepares ONDRI data for outlier analysis. <details><summary>License</summary>GNU General Public License Version 3.0</details> | R, RStudio, [GSVD](https://github.com/derekbeaton/GSVD) and [ours](https://github.com/derekbeaton/OuRS) R Packages | At the lab | ONDRI| 
| [Outliers (Shiny) App](https://github.com/ondri-nibs/outliers_app) | Performs outlier analyses on ONDRI data <details><summary>License</summary>GNU General Public License Version 3.2</details> | R, Rstudio | At the lab | ONDRI| 
| [OSIRIX](https://www.osirix-viewer.com/) | Software used for confirmation of de-identification of MRI data by EpLink researchers. <details><summary>License</summary>Perpetual License </details> <details><summary>Tool Citation(s) </summary> Rosset, A., Spadola, L., & Ratib, O. (2004). OsiriX: An Open-Source Software for Navigating in Multidimensional DICOM Images. Journal of Digital Imaging, 17(3), 205–216. https://doi.org/10.1007/s10278-004-1014-6 </details><details><summary>Relevant Publications</summary> [Ratib & Rosset, 2006](https://doi.org/10.1007/s11548-006-0056-2), [Vides Canas et al., 2007](https://doi.org/10.1109/IEMBS.2007.4352974), [Fortin & Battié, 2012](https://doi.org/10.2522/ptj.20110380), [Deora et al., 2020](https://doi.org/10.1016/j.wneu.2020.05.146) </details>| Only compatible on Mac Computers, >6 GB RAM | At the lab | EpLink |
| [MANGO](https://ric.uthscsa.edu/mango/mango.html) | Software used for confirmation of de-identification of MRI data by EpLink researchers. <details><summary>License</summary> Freeware License </details> <details><summary>Tool Citation(s) </summary> In-text citation:<br> Lancaster, Martinez; www.ric.uthscsa.edu/mango</details> <details><summary>Relevant Publications</summary> [Shih et al., 2011](https://doi.org/10.1038/jcbfm.2010.173), [Lancaster et al., 2012](https://www.frontiersin.org/articles/10.3389/fninf.2012.00023), [Dager et al., 2015](https://doi.org/10.1038/npp.2014.187), [Hassan et al., 2016](https://doi.org/10.1038/srep25295) </details> | N/A | At the lab | EpLink |
| [fMRIPrep](https://github.com/nipreps/fmriprep) | Preprocessing pipeline for task-based and resting-state functional MRI. <details><summary>License</summary>Apache Version 2.0</details><details><summary>Tool Citation(s)</summary> Esteban, O., Ciric, R., Finc, K., Blair, R. W., Markiewicz, C. J., Moodie, C. A., Kent, J. D., Goncalves, M., DuPre, E., Gomez, D. E. P., Ye, Z., Salo, T., Valabregue, R., Amlien, I. K., Liem, F., Jacoby, N., Stojić, H., Cieslak, M., Urchs, S., … Gorgolewski, K. J. (2020). Analysis of task-based functional MRI data preprocessed with fMRIPrep. Nature Protocols, 15(7), 2186–2202. https://doi.org/10.1038/s41596-020-0327-3 </br><br>Esteban, O., Markiewicz, C. J., Blair, R. W., Moodie, C. A., Isik, A. I., Erramuzpe, A., Kent, J. D., Goncalves, M., DuPre, E., Snyder, M., Oya, H., Ghosh, S. S., Wright, J., Durnez, J., Poldrack, R. A., & Gorgolewski, K. J. (2019). fMRIPrep: A robust preprocessing pipeline for functional MRI. Nature Methods, 16(1), 111–116. https://doi.org/10.1038/s41592-018-0235-4</details><details><summary>Relevant Publications</summary>[Ciric et al., 2018](https://doi.org/10.1038/s41596-018-0065-y), [Esteban et al., 2019](https://doi.org/10.1038/s41592-018-0235-4), [Nastase et al., 2019](https://doi.org/10.1093/scan/nsz037), [Botvinik-Nezer et al., 2020](https://doi.org/10.1038/s41586-020-2314-9), [Esteban et al., 2020](https://doi.org/10.1038/s41596-020-0327-3)</details> | N/A | At the lab | POND |
| [Bpipe](https://github.com/ssadedin/bpipe/) | Preprocessing pipeline (masking, image registration, etc). Needed for CIVET/MAGeT/Freesurfer.  <details><summary>License</summary>New BSD License</details><details><summary>Tool Citation(s)</summary>Sadedin S, Pope B & Oshlack A, Bpipe: A Tool for Running and Managing Bioinformatics Pipelines, Bioinformatics</details> <details><summary>Relevant Publications</summary>[Köster & Rahmann, 2012](https://doi.org/10.1093/bioinformatics/bts480), [Leipzig, 2017](https://doi.org/10.1093/bib/bbw020), [Germann et al., 2020](https://doi.org/10.1016/j.bpsc.2020.01.004), [Neudorfer et al., 2020](https://doi.org/10.1038/s41597-020-00644-6)</details> | N/A | At the lab | POND |
| [CIVET](http://www.bic.mni.mcgill.ca/ServicesSoftware/CIVET-2-1-0-Table-of-Contents) | Cortical morphometry pipeline that uses deformable models to fit and measure the human cortex. Similar function to Freesurfer. <details><summary>License</summary>https://github.com/aces/CIVET/blob/master/COPYING</details><details><summary>Tool Citation(s)</summary>Y. Ad-Dab'bagh et al., "The CIVET image-processing environment: A fully automated comprehensive pipeline for anatomical neuroimaging research", in "Proceedings of the 12th Annual Meeting of the Organization for Human Brain Mapping", M. Corbetta, ed. (Florence, Italy, NeuroImage), 2006</details><details><summary>Relevant Publications</summary>[Ad-Dab'bagh et al., 2006](https://www.bic.mni.mcgill.ca/users/yaddab/Yasser-HBM2006-Poster.pdf), [Bermudez et al., 2009](https://doi.org/10.1093/cercor/bhn196), [Gong et al., 2009](https://doi.org/10.1523/JNEUROSCI.2308-09.2009), [Seminowicz et al., 2011](https://doi.org/10.1523/JNEUROSCI.5280-10.2011)</details> | N/A | At the lab | POND |
| [MAGeT](https://github.com/CobraLab/MAGeTbrain) | General purpose segmentation pipeline that does automatic template generation for multi-atlas segmentation. <details><summary>License</summary>[Academic Public License](https://github.com/CoBrALab/MAGeTbrain/blob/simplified-labelmask/LICENSE)</details><details><summary>Tool Citation(s)</summary>Pipitone J, Park MT, Winterburn J, et al. Multi-atlas segmentation of the whole hippocampus and subfields using multiple automatically generated templates. Neuroimage. 2014<br></br> M Mallar Chakravarty, Patrick Steadman, Matthijs C van Eede, Rebecca D Calcott, Victoria Gu, Philip Shaw, Armin Raznahan, D Louis Collins, and Jason P Lerch. Performing label-fusion-based segmentation using multiple automatically generated templates. Hum Brain Mapp, 34(10):2635–54, October 2013. (doi:10.1002/hbm.22092)</details> <details><summary>Relevant Publications</summary>[Chakravarty et al., 2012](https://doi.org/10.1002/hbm.22092), [Park et al., 2014](https://doi.org/10.1016/j.neuroimage.2014.03.037), [Pipitone et al., 2014](https://doi.org/10.1016/j.neuroimage.2014.04.054), [Guo et al., 2015](https://doi.org/10.1016/j.nicl.2015.07.019)</details>| Python 3, [ANTs](http://stnava.github.io/ANTs/) (with MINC enabled), [minc-toolkit-v2](https://en.wikibooks.org/wiki/MINC/Introduction), [pyminc](https://github.com/Mouse-Imaging-Centre/pyminc), [minc-stuffs](https://github.com/Mouse-Imaging-Centre/minc-stuffs), [qbatch](https://github.com/pipitone/qbatch) (for cluster integration), [gnu-parallel](https://www.gnu.org/software/parallel/) | At the lab | POND |
| [Pydpiper](https://github.com/Mouse-Imaging-Centre/pydpiper) | Neuroimaging registration toolkit written in Python. <details><summary>License</summary>[Modified BSD License](https://github.com/Mouse-Imaging-Centre/pydpiper/blob/main/LICENSE)</details><details><summary>Tool Citation(s)</summary>Friedel, M., van Eede, M. C., Pipitone, J., Chakravarty, M. M., & Lerch, J. P. (2014). Pydpiper: A flexible toolkit for constructing novel registration pipelines. Frontiers in Neuroinformatics, 8. https://www.frontiersin.org/articles/10.3389/fninf.2014.00067 </details><details><summary>Relevant Publications</summary>[Friedel et al., 2014](https://www.frontiersin.org/articles/10.3389/fninf.2014.00067), [van der Plas et al., 2017](https://doi.org/10.1002/brb3.621), [Qiu et al., 2018](https://doi.org/10.1038/s41467-018-04921-2), [Yee et al., 2018](https://doi.org/10.1016/j.neuroimage.2018.05.028)</details>| N/A | At the lab | POND |
| [Minc-toolkit2](https://github.com/BIC-MNI/minc-toolkit-v2) | Set of software tools for advanced image processing, pipelining, statistical analysis, and visualization. <details><summary>License</summary>GNU General Public License Version 3.0 </details><details><summary>Tool Citation(s)</summary>MINC Toolkit. McConnell Brain Imaging Centre. Available at: http://www.bic.mni.mcgill.ca/ServicesSoftware/MINC. Accessed August 4, 2022.</details><details><summary>Relevant Publications</summary>[Xiao et al., 2017](https://doi.org/10.1002/mp.12268), [Zukotynski et al., 2020](https://doi.org/10.1097/RLU.0000000000003043), [Gaj et al., 2021](https://doi.org/10.1371/journal.pone.0255939), [Zeineldin et al., 2021](https://doi.org/10.1007/978-3-030-87589-3_60)</details>| N/A | At the lab | POND |

</details></blockquote>



<blockquote><details><summary>Data Analysis Pipeline</summary>
&nbsp

| Tool/Pipeline | Description | Requirements | Compute Location | Research Program(s) |
| ---------------- | ----------- | --------------------------- | ----------- | ---------|
| [Nilearn](https://github.com/nilearn/nilearn) | Python package that uses statistical and machine-learning tools to perform analyses on brain volumes such as feature parcellation, automated anatomical labeling (AAL), and connectivity estimation. <details><summary>License</summary>New BSD License </details><details><summary>Tool Citation(s)</summary>Abraham, A., Pedregosa, F., Eickenberg, M., Gervais, P., Mueller, A., Kossaifi, J., Gramfort, A., Thirion, B., & Varoquaux, G. (2014). Machine learning for neuroimaging with scikit-learn. Frontiers in Neuroinformatics, 8. https://www.frontiersin.org/articles/10.3389/fninf.2014.00014</details> <details><summary>**Relevant Publications**</summary></details> | matplotlib >= 3.0 | At the lab | CAN-BIND |
| [Scikit-learn](https://github.com/scikit-learn/scikit-learn) | Python package for machine learning that can be used to conduct correlations, partial correlations, tangents, logistic regression, gradient boosted decision trees (GBDT), random forest models, and Stochastic gradient descent (SGD) models. <details><summary>License</summary>BSD 3-Clause License </details><details><summary>Tool Citation(s)</summary>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, É. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12(85), 2825–2830. </details><details><summary>**Relevant Publications**</summary></details> | Python (>= 3.8), NumPy (>= 1.17.3), SciPy (>= 1.3.2), joblib (>= 1.0.0), threadpoolctl (>= 2.0.0) | At the lab | CAN-BIND |  
| [MATLAB - PLS Toolbox](https://www.mathworks.com/help/stats/plsregress.html) | MATLAB toolbox that is used to conduct statistical analysis of functional connectivity on fMRI data. <details><summary>**License**</summary> </details><details><summary>**Tool Citation(s)**</summary></details> <details><summary>**Relevant Publications**</summary></details>| N/A | At the lab | CAN-BIND |  
| [Fieldtrip - automated anatomical labeling (AAL) atlas](https://www.fieldtriptoolbox.org/template/atlas/#the-aal-atlas) | Atlas used for MRI spatial pattern analysis. <details><summary>License</summary>GNU General Public License Version 3.0 </details><details><summary>Tool Citation(s)</summary>N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, F. Crivello, O. Etard, N. Delcroix, B. Mazoyer, and M. Joliot. Automated Anatomical Labeling of Activations in SPM Using a Macroscopic Anatomical Parcellation of the MNI MRI Single-Subject Brain. NeuroImage 2002. 15:273-289. </details> <details><summary>**Relevant Publications**</summary></details> | N/A | At the lab | CAN-BIND |
| [MNI2TAL](https://bioimagesuiteweb.github.io/bisweb-manual/tools/mni2tal.html) | Tool used for manual inspection of neuroimaging clusters. <details><summary>**License**</summary> </details><details><summary>**Tool Citation(s)**</summary></details> <details><summary>**Relevant Publications**</summary></details>| N/A | At the lab | CAN-BIND |
| Statsmodels Python module | Tool used for statistical analysis of MRI data. <details><summary>License</summary> Modified BSD 3-clause License </details><details><summary>Tool Citation(s)</summary>Seabold, Skipper, and Josef Perktold. “statsmodels: Econometric and statistical modeling with python.” Proceedings of the 9th Python in Science Conference. 2010.</details> <details><summary>**Relevant Publications**</summary></details>| Python >= 3.7, NumPy >= 1.17, SciPy >= 1.3, Pandas >= 1.0, Patsy >= 0.5.2 | At the lab | CAN-BIND |
| Pingouin Python package | Tool used for statistical analysis of MRI data. <details><summary>License</summary> GNU General Public License Version 3.0 </details><details><summary>Tool Citation(s)</summary>Vallat, R. (2018). Pingouin: statistics in Python. Journal of Open Source Software, 3(31), 1026, https://doi.org/10.21105/joss.01026</details> <details><summary>**Relevant Publications**</summary></details>| NumPy, SciPy, Pandas, Pandas-flavor, Statsmodels, Matplotlib, Seaborn, Outdated Python packages | At the lab | CAN-BIND |
| [RStudio](https://www.rstudio.com/) | Used for data visualization for structural MRI data | N/A | At the lab | ONDRI |
| [MATLAB](https://www.mathworks.com/products/matlab.html) | Used for data visualization for structural MRI data | N/A | At the lab | CAN-BIND, ONDRI |
| [SPSS](https://www.ibm.com/products/spss-statistics?utm_content=SRCWW&p1=Search&p4=43700050715561164&p5=e&gclid=EAIaIQobChMIt-eJ2_Wo-QIV2vvjBx1mQwE9EAAYASAAEgJ0vfD_BwE&gclsrc=aw.ds) | Used for testing of hypotheses by ONDRI resarchers | N/A | At the lab | ONDRI |
| [Minc-toolkit2](https://github.com/BIC-MNI/minc-toolkit-v2) | Set of software tools for advanced image processing, pipelining, statistical analysis, and visualization. <details><summary>License</summary>GNU General Public License Version 3.0 </details><details><summary>Tool Citation(s)</summary>MINC Toolkit. McConnell Brain Imaging Centre. Available at: http://www.bic.mni.mcgill.ca/ServicesSoftware/MINC. Accessed August 4, 2022.</details><details><summary>Relevant Publications</summary>[Xiao et al., 2017](https://doi.org/10.1002/mp.12268), [Zukotynski et al., 2020](https://doi.org/10.1097/RLU.0000000000003043), [Gaj et al., 2021](https://doi.org/10.1371/journal.pone.0255939), [Zeineldin et al., 2021](https://doi.org/10.1007/978-3-030-87589-3_60)</details>| N/A | At the lab | POND |
| [FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL) | Library of analysis tools for fMRI, MRI, and DTI brain imaging data. <details><summary>License</summary> Oxford </details> <details><summary>Tool Citation(s)</summary>M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009 </br><br> S.M. Smith, M. Jenkinson, M.W. Woolrich, C.F. Beckmann, T.E.J. Behrens, H. Johansen-Berg, P.R. Bannister, M. De Luca, I. Drobnjak, D.E. Flitney, R. Niazy, J. Saunders, J. Vickers, Y. Zhang, N. De Stefano, J.M. Brady, and P.M. Matthews. Advances in functional and structural MR image analysis and implementation as FSL. NeuroImage, 23(S1):208-19, 2004 </br><br> M. Jenkinson, C.F. Beckmann, T.E. Behrens, M.W. Woolrich, S.M. Smith. FSL. NeuroImage, 62:782-90, 2012</details> <details><summary>Relevant Publications</summary> [Smith et al., 2004](https://doi.org/10.1016/j.neuroimage.2004.07.051), [Woolrich et al., 2009](https://doi.org/10.1016/j.neuroimage.2008.10.055), [Jenkinson et al., 2012](https://doi.org/10.1016/j.neuroimage.2011.09.015), [Schoemaker et al., 2016](https://doi.org/10.1016/j.neuroimage.2016.01.038) </details>| N/A | At the lab | POND |
   
</blockquote></details>
</details>

<details>
<summary>EEG</summary>
&nbsp 
<blockquote><details><summary> Data Collection Pipelines</summary>
&nbsp 
    
| Tool/Pipeline | Description | Requirements | Compute Location | Research Program(s) |
| ---------------- | ----------- | --------------------------- | ----------- | ---------|
| [Natus NeuroWorks EEG](https://neuro.natus.com/products-services/natus-neuroworks-eeg-software) | Data collection platform for EEG in the lab <details><summary>License</summary> Proprietary </details> <details><summary>Tool Citation(s) </summary> Natus products & services. https://neuro.natus.com/products-services </details> <details><summary>Relevant Publications</summary>[Stacey et al., 2013](https://doi.org/10.1111/epi.12202), [McKay et al., 2019](https://doi.org/10.1097/WNP.0000000000000603), [Baldwin et al., 2021](https://doi.org/10.1177/15500594211063710), [Nayak & Nattanmai, 2021](https://doi.org/10.1016/j.eplepsyres.2021.106623) </details>| Mid-size CPU | At the lab | EpLink|
</details></blockquote>

<blockquote><details><summary> Data Curation and Processing Pipelines</summary>
&nbsp 
    
| Tool/Pipeline | Description | Requirements | Compute Location | Research Program(s) |
| ---------------- | ----------- | --------------------------- | ----------- | ---------|
| Naming convention pipeline | Pipeline that re-names data to be more easily processed on SPReD.<details><summary>License</summary>Creative Commons Attribution 3.0</details> | N/A | [Brain-CODE](https://www.braincode.ca/) | All |
| [EEGLAB](https://sccn.ucsd.edu/eeglab/index.php) | Software that is used for the conversion of EEG data into EDF format and the normalization and standardization of EEG data. <details><summary>License</summary>MIT License </details> <details><summary>Tool Citation(s) </summary> Delorme, A., & Makeig, S. (2004). EEGLAB: An open source toolbox for analysis of single-trial EEG dynamics including independent component analysis. Journal of Neuroscience Methods, 134(1), 9–21. https://doi.org/10.1016/j.jneumeth.2003.10.009 </details> <details><summary>Relevant Publications</summary> [Delorme & Makeig, 2004](https://doi.org/10.1016/j.jneumeth.2003.10.009), [Makeig et al., 2004](https://doi.org/10.1016/j.tics.2004.03.008), [Delorme et al., 2007](https://doi.org/10.1016/j.neuroimage.2006.11.004), [Delorme et al., 2011](https://doi.org/10.1155/2011/130714), [Martínez-Cancino et al., 2021](https://doi.org/10.1016/j.neuroimage.2020.116778) </details>| MATLAB, > 8 GB and multi-core 64-bit processors recommended for large datasets | At the lab | CAN-BIND|
| [ERPEEG](https://github.com/EEGSignalProcessing/ERPEEG) | MATLAB app that is used for streamlined processing of ERP data <details><summary>License</summary> GNU General Public License Version 3.0 </details> <details><summary>Tool Citation(s) </summary> Farzan, F., Atluri, S., Frehlich, M., Dhami, P., Kleffner, K., Price, R., Lam, R. W., Frey, B. N., Milev, R., Ravindran, A., McAndrews, M. P., Wong, W., Blumberger, D., Daskalakis, Z. J., Vila-Rodriguez, F., Alonso, E., Brenner, C. A., Liotti, M., Dharsee, M., Kennedy, S. H. (2017). Standardization of electroencephalography for multi-site, multi-platform and multi-investigator studies: Insights from the canadian biomarker integration network in depression. Scientific Reports, 7, 7473. https://doi.org/10.1038/s41598-017-07613-x </details> <details><summary>Relevant Publications</summary>[ERPEEG Tutorial Document](http://www.tmseeg.com/wp-content/uploads/2018/03/ERPEEG-Tutorial-v2.0-March-2018.pdf) </details>| MATLAB, EEGLAB, FASTICA, tight_subplot.m | At the lab | CAN-BIND |
| [TMSEEG](http://www.tmseeg.com/) | Streamlined app that allows for EEG data collection during TMS application <details><summary>License</summary> GNU General Public License Version 3.0 </details> <details><summary>Tool Citation(s) </summary> Atluri, S., Frehlich, M., Mei, Y., Garcia Dominguez, L., Rogasch, N. C., Wong, W., Daskalakis, Z. J., & Farzan, F. (2016). TMSEEG: A MATLAB-Based Graphical User Interface for Processing Electrophysiological Signals during Transcranial Magnetic Stimulation. Frontiers in Neural Circuits, 10. https://www.frontiersin.org/articles/10.3389/fncir.2016.00078 </details> <details><summary>Relevant Publications</summary> [Atluri et al., 2016](https://www.frontiersin.org/articles/10.3389/fncir.2016.00078), [Farzan et al., 2017](https://doi.org/10.1038/s41598-017-07613-x), [Tremblay et al., 2019](https://doi.org/10.1016/j.clinph.2019.01.001), [Dhami et al., 2020](https://doi.org/10.1093/cercor/bhaa004), [Bertazzoli et al., 2021](https://doi.org/10.1016/j.neuroimage.2021.118272) </details> | MATLAB, EEGLAB, FASTICA, tight_subplot.m | At the lab | CAN-BIND |
| [Standards (Shiny) App](https://github.com/ondri-nibs/standards_app) | Performs standard checks on ONDRI data <details><summary>License</summary>GNU General Public License Version 3.1</details> | R, Rstudio | At the lab | ONDRI| 
| [Data Preparation (Shiny) App](https://github.com/ondri-nibs/dataprep_app) | Prepares ONDRI data for outlier analysis. <details><summary>License</summary>GNU General Public License Version 3.0</details> | R, RStudio, [GSVD](https://github.com/derekbeaton/GSVD) and [ours](https://github.com/derekbeaton/OuRS) R Packages | At the lab | ONDRI| 
| [Outliers (Shiny) App](https://github.com/ondri-nibs/outliers_app) | Performs outlier analyses on ONDRI data <details><summary>License</summary>GNU General Public License Version 3.2</details> | R, Rstudio | At the lab | ONDRI| 
| [DATA2BIDS](https://github.com/SIMEXP/Data2Bids) | Software that assists in the acquisition of EEG data and the conversion of EEG data to EDF format and packaging to BIDS format. <details><summary>License</summary> MIT License </details> <details><summary>Tool Citation(s) </summary> Oostenveld, R., Fries, P., Maris, E., & Schoffelen, J.-M. (2010). FieldTrip: Open Source Software for Advanced Analysis of MEG, EEG, and Invasive Electrophysiological Data. Computational Intelligence and Neuroscience, 2011, e156869. https://doi.org/10.1155/2011/156869 </details> <details><summary>Relevant Publications</summary>[Oostenveld et al., 2010](https://doi.org/10.1155/2011/156869), [Holdgraf et al., 2019](https://doi.org/10.1038/s41597-019-0105-7), [Pernet et al., 2019](https://doi.org/10.1038/s41597-019-0104-8), [Schoffelen et al., 2019](https://doi.org/10.1038/s41597-019-0020-y), [Vaghari et al., 2022](https://doi.org/10.1016/j.neuroimage.2022.119344) </details> | [BIDS Validator](https://github.com/bids-standard/bids-validator), [nibabel](https://nipy.org/nibabel/), [numpy](https://numpy.org/) | [Brain-CODE](https://www.braincode.ca/) | EpLink |

</details></blockquote>

<blockquote><details><summary> Data Analysis Pipelines</summary></details></blockquote>
    
</details>

<details>
<summary>DTI</summary>
&nbsp 
<blockquote><details><summary> Data Collection Pipelines</summary>
&nbsp
DTI data is collected and processed in the DTI machine before undergoing data curation and processing.
</details></blockquote>
  
<blockquote><details><summary> Data Curation and Processing Pipelines</summary>
&nbsp
    
| Tool/Pipeline | Description | Requirements | Compute Location | Research Program(s) |
| ---------------- | ----------- | --------------------------- | ----------- | ---------|
| [SABRE](https://sabre.brainlab.ca/docs/index.html#) | Pipeline used for segmentation of regions of interest in DTI data. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s) </summary> Dade L.A., Gao F.Q., Kovacevic N., Roy P., Rockel C., O'Toole C.M., Lobaugh N.J., Feinstein A., Levine B., Black S.E.  (2004).  Semiautomatic brain region extraction: a method of parcellating brain regions from structural magnetic resonance images. Neuroimage, 22, 1492-502. </details> <details><summary>Relevant Publications</summary> [Dade et.al., 2004](https://doi.org/10.1016/j.neuroimage.2004.03.023), [Ramirez et.al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.013), [Ramirez et.al., 2013](https://doi.org/10.1007/s10548-012-0228-z), [Ramirez et.al., 2020](https://www.frontiersin.org/articles/10.3389/fneur.2020.00847) </details> | N/A | At the lab | ONDRI |
| [Lesion Explorer](https://sabre.brainlab.ca/docs/processing/stage7.html#lesion-explorer-le) | Tool used for segmentation of regions of interest, automatic identification of white matter hyperintensities, and capturing of enlarged periventricular spaces in DTI data. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s) </summary> Ramirez, J., Scott, C. J. M., McNeely, A. A., Berezuk, C., Gao, F., Szilagyi, G. M., & Black, S. E. (2014). Lesion Explorer: A Video-guided, Standardized Protocol for Accurate and Reliable MRI-derived Volumetrics in Alzheimer’s Disease and Normal Elderly. JoVE (Journal of Visualized Experiments), 86, e50887. https://doi.org/10.3791/50887 </br><br>Ramirez, J., Gibson, E., Quddus, A., Lobaugh, N. J., Feinstein, A., Levine, B., Scott, C. J. M., Levy-Cooperman, N., Gao, F. Q., & Black, S. E. (2011). Lesion Explorer: A comprehensive segmentation and parcellation package to obtain regional volumetrics for subcortical hyperintensities and intracranial tissue. NeuroImage, 54(2), 963–973. https://doi.org/10.1016/j.neuroimage.2010.09.013 </details><details><summary>Relevant Publications</summary> [Ramirez et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.013), [Ramirez et al., 2013](https://doi.org/10.1007/s10548-012-0228-z), [Ramirez et al., 2014](https://doi.org/10.3233/JAD-132528), [Haddad et al., 2019](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6924651/) </details>| N/A | At the lab | ONDRI |
| [FLEX](https://sabre.brainlab.ca/docs/processing/stage7.html#fuzzy-lesion-extractor-flex-coming-soon) (Coming soon!) | Tool used for segmentation of regions of interest and automatic identification of white matter hyperintensities in DTI data. <details><summary>License</summary>GNU General Public License Version 3.0</details> <details><summary>Tool Citation(s)</summary>Gibson E., Gao F., Black S.E., Lobaugh N.J.  (2010).  Automatic segmentation of white matter hyperintensities in the elderly using FLAIR images at 3T. Journal of Magnetic Resonance Imaging, 31, 1311-22.</details> <details><summary>Relevant Publications</summary> [Borghesani et al., 2013](https://doi.org/10.1016/j.neuropsychologia.2013.03.005), [Makedonov et al., 2013](https://doi.org/10.1371/journal.pone.0067652), [Huang et al., 2014](https://doi.org/10.1016/j.psyneuen.2013.09.027), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details> | N/A | At the lab | ONDRI |
| [FSL - FAST](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FAST?highlight=%28mfast%29) (Previously mfast) | Software used for conduction of bias field correction in DTI data. <details><summary>License</summary> Oxford </details> <details><summary>Tool Citation(s) </summary> Zhang, Y. and Brady, M. and Smith, S. Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm. IEEE Trans Med Imag, 20(1):45-57, 2001. </details> <details><summary>Relevant Publications</summary> [Smith et al., 2004]( https://doi.org/10.1016/j.neuroimage.2004.07.051), [Gibson et al., 2010](https://doi.org/10.1002/jmri.22004), [Glasser et al., 2013](https://doi.org/10.1016/j.neuroimage.2013.04.127), [Droby et al., 2021](https://doi.org/10.1371/journal.pone.0254597) </details> | >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI |
| [3D Slicer - Rician LMMSE Image Filter Module](https://www.slicer.org/wiki/Modules:RicianLMMSEImageFilter-Documentation-3.6) | DTI data is moderately filtered to alleviate the effect of the Rician noise. Accepts NRRD format. <details><summary>License</summary>[BSD-style open source license](https://slicer.readthedocs.io/en/latest/user_guide/about.html#license)</details> <details><summary>Tool Citation(s)</summary>S. Aja-Fernandez, M. Niethammer, M. Kubicki, M. E. Shenton, and C.-F. Westin, “Restoration of DWI data using a Rician LMMSE estimator.,” IEEE Trans. Med. Imaging, vol. 27, no. 10, pp. 1389– 403, Oct. 2008, doi: 10.1109/TMI.2008.920609.</details> <details><summary>Relevant Publications</summary> [Froeling et al., 2012](https://doi.org/10.1002/jmri.23608), [Manjón et al., 2013](https://doi.org/10.1371/journal.pone.0073021), [Mohan et al., 2014](https://doi.org/10.1016/j.bspc.2013.10.007), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details>| > 4 GB memory, minimum OpenGL 3.2, discrete graphics card, GPU texture memory (VRAM) should be larger than your largest dataset, 3D Slicer. | At the lab | ONDRI |    
| [DTIPrep](https://www.nitrc.org/projects/dtiprep/) | Takes output of Filter. Applied to DTI data to reject the diffusion volumes affected by various DWI artifacts and corrects the DTI data for eddy current and motion artifacts. <details><summary>License</summary>Apache Version 2.0</details>  <details><summary>Tool Citation(s)</summary>I. Oguz et al., “DTIPrep: quality control of diffusion-weighted images,” Front. Neuroinform., vol. 8, p. 4, 2014, doi: 10.3389/fninf.2014.00004.</details> <details><summary>Relevant Publications</summary> [Roalf et al., 2016](https://doi.org/10.1016/j.neuroimage.2015.10.068), [O’Donnell et al., 2017](https://doi.org/10.1016/j.nicl.2016.11.023), [Zhang et al., 2018](https://doi.org/10.1016/j.neuroimage.2018.06.027), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details>| N/A | At the lab | ONDRI |
| [Camino - RESTORE algorithm](https://www.nitrc.org/projects/camino/) | Conducts robust tensorfitting to estimate voxelwise diffusion tensors from the DTI data using an iteratively reweighted least-square regression algorithm. Used to capture and remove outlier voxels from the tensor fitting. <details><summary>License</summary>Artistic License</details> <details><summary>Tool Citation(s)</summary>L.-C. Chang, D. K. Jones, and C. Pierpaoli, “RESTORE: Robust estimation of tensors by outlier rejection,” Magn. Reson. Med., vol. 53, no. 5, pp. 1088–1095, May 2005.</details> <details><summary>Relevant Publications</summary>[Chang et al., 2005](https://doi.org/10.1002/mrm.20426), [Cook et al., 2005](https://doi.org/10.54294/fgfrtv), [Jones et al., 2013](https://doi.org/10.1016/j.neuroimage.2012.06.081), [Soares et al., 2013](https://www.frontiersin.org/articles/10.3389/fnins.2013.00031), [Garyfallidis et al., 2014](https://www.frontiersin.org/articles/10.3389/fninf.2014.00008), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details>| N/A | At the lab | ONDRI |
| [MATLAB](https://www.mathworks.com/campaigns/offers/matlab-toolbox-price-request.htmlgclid=Cj0KCQjw54iXBhCXARIsADWpsG9c133Siu49Rpp5lla8mCoXpliAalddr5nCzzGnNvDhs1Nf01hfrUEaAlAUEALw_wcB&ef_id=Cj0KCQjw54iXBhCXARIsADWpsG9c133Siu49Rpp5lla8mCoXpliAalddr5nCzzGnNvDhs1Nf01hfrUEaAlAUEALw_wcB:G:s&s_kwcid=AL!8664!3!606527715283!p!!g!!get%20matlab&s_eid=ppc_62715809977&q=get%20matlab) code | Voxel wise DTI metric check up, removing voxels with negative eigenvalues or with MD, AD, AND RD higher than 5.5 mm2/sec. | N/A | At the lab | ONDRI |    
| [Data Preparation (Shiny) App](https://github.com/ondri-nibs/dataprep_app) | Prepares ONDRI data for outlier analysis. <details><summary>License</summary>GNU General Public License Version 3.0</details> | R, RStudio, [GSVD](https://github.com/derekbeaton/GSVD) and [ours](https://github.com/derekbeaton/OuRS) R Packages | At the lab | ONDRI| 
| [Outliers (Shiny) App](https://github.com/ondri-nibs/outliers_app) | Performs outlier analyses on ONDRI data. <details><summary>License</summary>GNU General Public License Version 3.2</details> | R, Rstudio | At the lab | ONDRI| 
| [QSIprep](https://github.com/PennLINC/qsiprep) | Preprocessing pipeline for diffusion MRI. <details><summary>License</summary>BSD-3-Clause License</details><details><summary>Tool Citation(s)</summary>Cieslak, M., Cook, P. A., He, X., Yeh, F.-C., Dhollander, T., Adebimpe, A., Aguirre, G. K., Bassett, D. S., Betzel, R. F., Bourque, J., Cabral, L. M., Davatzikos, C., Detre, J. A., Earl, E., Elliott, M. A., Fadnavis, S., Fair, D. A., Foran, W., Fotiadis, P., … Satterthwaite, T. D. (2021). QSIPrep: An integrative platform for preprocessing and reconstructing diffusion MRI data. Nature Methods, 18(7), 775–778. https://doi.org/10.1038/s41592-021-01185-5 </details> <details><summary>Relevant Publications</summary>[Cieslak et al., 2021](https://doi.org/10.1038/s41592-021-01185-5), [Kruper et al., 2021](https://doi.org/10.52294/e6198273-b8e3-4b63-babb-6e6b0da10669), [Teich et al., 2021](https://doi.org/10.1088/1367-2630/ac1286), [Tax et al., 2022](https://doi.org/10.1016/j.neuroimage.2021.118830)</details> | N/A | At the lab | POND |
    
</details></blockquote>

<blockquote><details><summary> Data Analysis Pipelines</summary>
&nbsp
    
| Tool/Pipeline | Description | Requirements | Compute Location | Research Program(s) |
| ---------------- | ----------- | --------------------------- | ----------- | ---------|
| [3D Slicer - DWIConverter Module](https://www.slicer.org/wiki/Documentation/Nightly/Modules/DWIConverter) | Converts data to NIFTI format. Converts the raw DTI data to NRRD format. Converts the quality controlled DTI data obtanined from DTIPrep in NRRD format to NIFTI format. <details><summary>License</summary>[BSD-style open source license](https://slicer.readthedocs.io/en/latest/user_guide/about.html#license)</details> <details><summary>Tool Citation(s)</summary>3D Slicer. [cited 02 Aug 2022]. https://www.slicer.org/ </br><br>Kikinis R, Pieper SD, Vosburgh KG. 3D Slicer: A Platform for Subject-Specific Image Analysis, Visualization, and Clinical Support. Intraoperative Imaging and Image-Guided Therapy. New York, NY: Springer New York; 2014. pp. 277–289. https://doi.org/10.1007/978-1-4614-7657-3_19</details> <details><summary>Relevant Publications</summary>[Kikinis et al., 2014](https://doi.org/10.1007/978-1-4614-7657-3_19),[ Young et al., 2017](https://www.frontiersin.org/articles/10.3389/fnins.2017.00029), [Janson & Butson, 2018](https://doi.org/10.3791/57292), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715), [Zhang et al., 2019](https://doi.org/10.21595/chs.2019.20724) </details>| > 4 GB memory, minimum OpenGL 3.2, discrete graphics card, GPU texture memory (VRAM) should be larger than your largest dataset, 3D Slicer. | At the lab | ONDRI |   
| [3D Slicer - Robust Brain Extraction (ROBEX) Module](https://www.slicer.org/wiki/Documentation/Nightly/Modules/ROBEXBrainExtraction) | Performs skull stripping. <details><summary>License</summary>[BSD-style open source license](https://slicer.readthedocs.io/en/latest/user_guide/about.html#license)</details> <details><summary>Tool Citation(s)</summary>3D Slicer. [cited 02 Aug 2022]. https://www.slicer.org/ </br><br>Iglesias JE, Liu CY, Thompson P, Tu Z: "Robust Brain Extraction Across Datasets and Comparison with Publicly Available Methods", IEEE Transactions on Medical Imaging, 30(9), 2011, 1617-1634.</details> <details><summary>Relevant Publications</summary> [Nir et al., 2013](https://doi.org/10.1016/j.nicl.2013.07.006), [Kleesiek et al., 2016](https://doi.org/10.1016/j.neuroimage.2016.01.024), [Baur et al., 2019](https://doi.org/10.1007/978-3-030-11723-8_16), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715), [Isensee et al., 2019](https://doi.org/10.1002/hbm.24750) </details> | > 4 GB memory, minimum OpenGL 3.2, discrete graphics card, GPU texture memory (VRAM) should be larger than your largest dataset, 3D Slicer. | At the lab | ONDRI | 
| [FSL - FLIRT](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT) | Used for linear registration of DTI data to T1 images. <details><summary>License</summary> Oxford </details> <details><summary>Tool Citation(s) </summary> M. Jenkinson and S.M. Smith. A global optimisation method for robust affine registration of brain images. Medical Image Analysis, 5(2):143-156, 2001.</br> <br>M. Jenkinson, P.R. Bannister, J.M. Brady, and S.M. Smith. Improved optimisation for the robust and accurate linear registration and motion correction of brain images. NeuroImage, 17(2):825-841, 2002.</br> <br>Greve, D.N. and Fischl, B. Accurate and robust brain image alignment using boundary-based registration. NeuroImage, 48(1):63-72, 2009. </br> </details> <details><summary>Relevant Publications</summary>[Jenkinson & Smith, 2001](https://doi.org/10.1016/s1361-8415(01)00036-6), [Smith et al., 2004](https://doi.org/10.1016/j.neuroimage.2004.07.051), [Lancaster et al., 2007](https://doi.org/10.1002/hbm.20345), [Ramirez et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.013), [Jenkinson et al., 2012](https://doi.org/10.1016/j.neuroimage.2011.09.015), [Muschelli et al., 2015](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4911193/), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details> | >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI | 
| [FSL - BBR](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT_BBR)  | Used for further adjustments for linear registration to T1 mask. Used for linear registration of the b0 volume in the DTI data to the corresponding T1-weighted image. <details><summary>License</summary> Oxford </details> <details><summary>Tool Citation(s) </summary> Greve DN, Fischl B. Accurate and robust brain image alignment using boundary-based registration. Neuroimage. 2009 Oct 15;48(1):63-72. </details> <details><summary>Relevant Publications</summary> [Greve & Fischl, 2009](https://doi.org/10.1016/j.neuroimage.2009.06.060), [Glasser et al., 2013](https://doi.org/10.1016/j.neuroimage.2013.04.127), [Griffanti et al., 2014](https://doi.org/10.1016/j.neuroimage.2014.03.034), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details>| >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI |
| [FSL - BET2](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET/UserGuide) | Performs skull stripping on DTI data. <details><summary>License</summary> Oxford </details> <details><summary>Tool Citation(s) </summary> M. Jenkinson, M. Pechaud, and S. Smith. BET2: MR-based estimation of brain, skull and scalp surfaces. In Eleventh Annual Meeting of the Organization for Human Brain Mapping, 2005. </details> <details><summary>Relevant Publications</summary> [Smith et al., 2004](https://doi.org/10.1016/j.neuroimage.2004.07.051), [Smith et al., 2006](https://doi.org/10.1016/j.neuroimage.2006.02.024), [Nestor et al., 2013](https://doi.org/10.1016/j.neuroimage.2012.10.081), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715), [Cengiz et al., 2022](https://doi.org/10.1007/s10334-022-01030-6), [Diaz-Hurtado et al., 2022](https://doi.org/10.1007/s00234-022-03019-3) </details>| >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI | 
| [FSL - FLIRT - applyxfm4D](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT/UserGuide) | Applies the transformation obtained from the previous step (BBR) to all the gradient volumes in DTI data to transfer the DTI data to the native T1-weighted space. <details><summary>License</summary> Oxford </details> <details><summary>Tool Citation(s) </summary> M. Jenkinson and S.M. Smith. A global optimisation method for robust affine registration of brain images. Medical Image Analysis, 5(2):143-156, 2001.</br> <br>M. Jenkinson, P.R. Bannister, J.M. Brady, and S.M. Smith. Improved optimisation for the robust and accurate linear registration and motion correction of brain images. NeuroImage, 17(2):825-841, 2002.</br> <br>Greve, D.N. and Fischl, B. Accurate and robust brain image alignment using boundary-based registration. NeuroImage, 48(1):63-72, 2009. </br> </details> <details><summary>Relevant Publications</summary> [Losnegård et al., 2013](https://www.frontiersin.org/articles/10.3389/fninf.2013.00013), [Kumar et al., 2017](https://doi.org/10.1016/j.neuroimage.2017.06.083), [Gilbert et al., 2019](https://doi.org/10.1172/JCI123743), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details> | >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI |
| [ANTs - SyN Registration Algorithm](http://stnava.github.io/ANTs/) | Used for non-linear registration of the b=0 image in the DTI data to the T2-weighted image. Used to remove EPI artifacts. <details><summary>License</summary>Apache Version 2.0 </details> <details><summary>Tool Citation(s) </summary>B. B. Avants, C. L. Epstein, M. Grossman, and J. C. Gee, “Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain,” Med. Image Anal., vol. 12, no. 1, pp. 26–41, Feb. 2008. </br><br> A. Klein et al., “Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration,” Neuroimage, vol. 46, no. 3, pp. 786–802, Jul. 2009. </details> <details><summary>Relevant Publications</summary> [Klein et al., 2010](https://doi.org/10.1016/j.neuroimage.2010.01.091), [Avants et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.025), [Schwarz et al., 2014](https://doi.org/10.1016/j.neuroimage.2014.03.026), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715), [Kuang & Schmah, 2019](https://doi.org/10.1007/978-3-030-32692-0_74) </details>| [ANTs](http://stnava.github.io/ANTs/) | At the lab | ONDRI | 
| [ANTs - antsApplyTransforms](http://stnava.github.io/ANTs/) | Used for multiresolution nonlinear registration of DTI data to registered T2 images. <details><summary>License</summary>Apache Version 2.0 </details> <details><summary>Tool Citation(s) </summary>B. B. Avants, C. L. Epstein, M. Grossman, and J. C. Gee, “Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain,” Med. Image Anal., vol. 12, no. 1, pp. 26–41, Feb. 2008. </br><br> A. Klein et al., “Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration,” Neuroimage, vol. 46, no. 3, pp. 786–802, Jul. 2009. </details> <details><summary>Relevant Publications</summary> [Claudiu et al., 2016](https://doi.org/10.3389/conf.fninf.2016.20.00064), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715), [Malagurski et al., 2020](https://doi.org/10.1002/hbm.25161), [Visconti di Oleggio Castello et al., 2020](https://doi.org/10.1038/s41597-020-00735-4), [Yang et al., 2020](https://doi.org/10.1016/j.neuroimage.2020.117340) </details>| [ANTs](http://stnava.github.io/ANTs/) | At the lab | ONDRI | 
| [Camino - RESTORE algorithm](https://www.nitrc.org/projects/camino/) | Conducts robust tensorfitting to estimate voxelwise diffusion tensors from the DTI data using an iteratively reweighted least-square regression algorithm. Used to capture and remove outlier voxels from the tensor fitting. <details><summary>License</summary>Artistic License</details> <details><summary>Tool Citation(s)</summary> L.-C. Chang, D. K. Jones, and C. Pierpaoli, “RESTORE: Robust estimation of tensors by outlier rejection,” Magn. Reson. Med., vol. 53, no. 5, pp. 1088–1095, May 2005. </details> <details><summary>Relevant Publications</summary>[Chang et al., 2005](https://doi.org/10.1002/mrm.20426), [Cook et al., 2005](https://doi.org/10.54294/fgfrtv), [Jones et al., 2013](https://doi.org/10.1016/j.neuroimage.2012.06.081), [Soares et al., 2013](https://www.frontiersin.org/articles/10.3389/fnins.2013.00031), [Garyfallidis et al., 2014](https://www.frontiersin.org/articles/10.3389/fninf.2014.00008), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715) </details>| N/A | At the lab | ONDRI | 
| [FSL - dtifit](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FDT/UserGuide#DTIFIT) | DTI scalar metrics calculation. <details><summary>License</summary> Oxford </details> <details><summary>Tool Citation(s)</summary>Behrens TEJ, Woolrich MW, Jenkinson M, Johansen-Berg H, Nunes RG, Clare S, et al. Characterization and propagation of uncertainty in diffusion-weighted MR imaging. Magn Reson Med. 2003; 50: 1077–1088. https://doi.org/10.1002/mrm.10609 PMID: 14587019 </br><br> Behrens TEJ, Berg HJ, Jbabdi S, Rushworth MFS, Woolrich MW. Probabilistic diffusion tractography with multiple fibre orientations: What can we gain? Neuroimage. 2007; 34: 144–155. https://doi.org/10. 1016/j.neuroimage.2006.09.018 PMID: 17070705</details> <details><summary>Relevant Publications</summary> [Bennett & Stark, 2016](https://doi.org/10.1016/j.nlm.2015.06.014), [Haddad et al., 2019](https://doi.org/10.1371/journal.pone.0226715), [Chad et al., 2021](https://doi.org/10.1016/j.neurobiolaging.2020.12.020), [Chen et al., 2021](https://doi.org/10.1016/j.mri.2021.06.012) </details> | >16 GB RAM, Swap space at least equal to GB of RAM, Disk space at least 10 times the size of data sets, FSL | At the lab | ONDRI | 
| [MATLAB](https://www.mathworks.com/products/matlab.html) | Conducts region of interest (ROI) analysis based on the regions provided by ONDRI SABRE lesion masks. | N/A | At the lab | ONDRI | 
| [Mritrix](https://www.mrtrix.org/) | Set of tools for DTI analyses. <details><summary>License</summary>Mozilla Public License 2.0</details> <details><summary>Tool Citation(s)</summary>J.-D. Tournier, R. E. Smith, D. Raffelt, R. Tabbara, T. Dhollander, M. Pietsch, D. Christiaens, B. Jeurissen, C.-H. Yeh, and A. Connelly. MRtrix3: A fast, flexible and open software framework for medical image processing and visualisation. NeuroImage, 202 (2019), pp. 116–37.</details> <details><summary>Relevant Publications</summary>[Raffelt et al., 2017](https://doi.org/10.1016/j.neuroimage.2016.09.029), [Cordero-Grande et al., 2019](https://doi.org/10.1016/j.neuroimage.2019.06.039), [Dhollander et al., 2019](https://www.researchgate.net/publication/331165168_Improved_white_matter_response_function_estimation_for_3-tissue_constrained_spherical_deconvolution), [Tournier et al., 2019](https://doi.org/10.1016/j.neuroimage.2019.116137)</details> | N/A | At the lab | POND |

</details></blockquote>
</details>

<details>
<summary>TMS</summary>
&nbsp 
<blockquote><details><summary> Data Collection Pipelines</summary></details></blockquote>
  
<blockquote><details><summary> Data Curation and Processing Pipelines</summary></details></blockquote>

<blockquote><details><summary> Data Analysis Pipelines</summary></details></blockquote>
</details>

<details>
<summary>CT</summary>
&nbsp 
<blockquote><details><summary> Data Collection Pipelines</summary></details></blockquote>
  
<blockquote><details><summary> Data Curation and Processing Pipelines</summary></details></blockquote>

<blockquote><details><summary> Data Analysis Pipelines</summary></details></blockquote>
</details>

<details>
<summary>PET</summary>
&nbsp 
<blockquote><details><summary> Data Collection Pipelines</summary></details></blockquote>
  
<blockquote><details><summary> Data Curation and Processing Pipelines</summary></details></blockquote>

<blockquote><details><summary> Data Analysis Pipelines</summary></details></blockquote>
</details>

<details>
<summary>MEG</summary>
&nbsp 
<blockquote><details><summary> Data Collection Pipelines</summary></details></blockquote>
  
<blockquote><details><summary> Data Curation and Processing Pipelines</summary></details></blockquote>

<blockquote><details><summary> Data Analysis Pipelines</summary></details></blockquote>
</details>
